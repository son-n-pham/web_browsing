{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyautogui\n",
    "# !pip install mss\n",
    "!pip uninstall pywinauto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import mss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'left': -1383, 'top': -1328, 'width': 5560, 'height': 2408},\n",
       " {'left': 0, 'top': 0, 'width': 1920, 'height': 1080},\n",
       " {'left': -303, 'top': -1080, 'width': 2560, 'height': 1080},\n",
       " {'left': 2257, 'top': -1090, 'width': 1920, 'height': 1080},\n",
       " {'left': -1383, 'top': -1328, 'width': 1080, 'height': 1920}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitors = mss.mss().monitors\n",
    "monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open browser window and go to chat.openai.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import mss\n",
    "import time\n",
    "\n",
    "location_search_bar = {'x': 750, 'y': 1055}\n",
    "location_browser_address_bar = {'x': 400, 'y': 65}\n",
    "web_browser = 'Edge'\n",
    "url = 'https://chat.openai.com/'\n",
    "\n",
    "def wait_for_new_window(old_windows, title):\n",
    "    while True:\n",
    "        new_windows = pyautogui.getWindowsWithTitle(title)\n",
    "        new_window = [window for window in new_windows if window not in old_windows]\n",
    "        if new_window:\n",
    "            return new_window[0]\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def wait_for_maximize(window):\n",
    "    while True:\n",
    "        if window.isMaximized:\n",
    "            return\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def open_webpage(location_search_bar, location_browser_address_bar, web_browser, url):\n",
    "    # Get a list of all currently open Edge windows\n",
    "    old_windows = pyautogui.getWindowsWithTitle(web_browser)\n",
    "\n",
    "    # Step 1: Open Edge browser\n",
    "    # Location of the search bar on the screen\n",
    "    pyautogui.click(x=location_search_bar[\"x\"], y=location_search_bar[\"y\"])\n",
    "    pyautogui.write(web_browser)\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "    # Wait for the new browser window to open\n",
    "    new_window = wait_for_new_window(old_windows, web_browser)\n",
    "\n",
    "    # Get the information of the first monitor\n",
    "    monitor = mss.mss().monitors[1]\n",
    "\n",
    "    # Move the new Edge browser window to the first monitor\n",
    "    new_window.moveTo(monitor[\"left\"], monitor[\"top\"])\n",
    "\n",
    "    # Maximize the Edge browser window\n",
    "    pyautogui.hotkey('alt', 'space')\n",
    "    pyautogui.press('x')\n",
    "\n",
    "    # Wait for the window to be maximized\n",
    "    wait_for_maximize(new_window)\n",
    "\n",
    "    # Step 2: Click on the browser address bar\n",
    "    pyautogui.click(x=location_browser_address_bar[\"x\"], y=location_browser_address_bar[\"y\"])  \n",
    "\n",
    "    # Step 3: Type the URL\n",
    "    pyautogui.write(url)\n",
    "\n",
    "    # Step 4: Press enter to go to the webpage\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "open_webpage(location_search_bar, location_browser_address_bar, web_browser, url)\n",
    "\n",
    "location_send_message = {'x':820, 'y':960}\n",
    "message = \"Give me a shorter poem.\"\n",
    "def send_message(location_send_message, message):\n",
    "    pyautogui.click(x=location_send_message[\"x\"], y=location_send_message[\"y\"])\n",
    "    pyautogui.write(message)\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "send_message(location_send_message, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Send message to chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "location_send_message = {'x':820, 'y':960}\n",
    "message = \"Give me a shorter poem.\"\n",
    "def send_message(location_send_message, message):\n",
    "    pyautogui.click(x=location_send_message[\"x\"], y=location_send_message[\"y\"])\n",
    "    pyautogui.write(message)\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "send_message(location_send_message, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Copy contents of chat window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import pyperclip\n",
    "import time\n",
    "\n",
    "# Open inspection of the webpage\n",
    "pyautogui.hotkey('ctrl', 'u')  # Use 'cmd' instead of 'ctrl' on macOS\n",
    "\n",
    "# Select all text\n",
    "pyautogui.hotkey('ctrl', 'a')  # Use 'cmd' instead of 'ctrl' on macOS\n",
    "\n",
    "# Copy the selected text\n",
    "pyautogui.hotkey('ctrl', 'c')  # Use 'cmd' instead of 'ctrl' on macOS\n",
    "\n",
    "# Wait for the clipboard to be updated\n",
    "time.sleep(0.2)\n",
    "\n",
    "# Get the copied text\n",
    "copied_text = pyperclip.paste()\n",
    "\n",
    "print(copied_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat history\n",
      "New Chat\n",
      "Close sidebar\n",
      "Today\n",
      "Short Starry Night Poem\n",
      "Learn English Presentation Skills\n",
      "Heritage, Nationality, and Residence\n",
      "Yesterday\n",
      "Hello and assistance.\n",
      "Previous 7 Days\n",
      "New chat\n",
      "Bible and Palestine Connection\n",
      "Xuất hiện khoa học dữ liệu\n",
      "Bible: Canaan, Philistines, Palestine\n",
      "Meaning of Edo\n",
      "Japan's Waste Classification System\n",
      "Previous 30 Days\n",
      "New chat\n",
      "New chat\n",
      "New chat\n",
      "Cursed Child Canon Discussion\n",
      "New chat\n",
      "Feeding Guppies for Vacation\n",
      "Clarify Criteria for Rating\n",
      "Safe Burger Storage Time\n",
      "Python Harry Potter Quiz\n",
      "Disney Princess Quote Game\n",
      "Fix UnboundLocalError using global\n",
      "Linking Tables in Power BI\n",
      "Langchain for Local Models\n",
      "Max_length Solution for Langchain\n",
      "AI Chat Support\n",
      "Black & White Effects\n",
      "Fixing \"conda not recognized\"\n",
      "Theoretical Rankings\n",
      "Code Refactoring: Streamlit Application\n",
      "Sentence vs Word Embeddings\n",
      "New chat\n",
      "Transplanting succulents safely.\n",
      "September\n",
      "GPT Chat in Streamlit\n",
      "\n",
      "\n",
      "Phosphorus Appearance Clarified\n",
      "Fantasy Potion Ideas\n",
      "Potion-making game: 10 elixirs\n",
      "Character Descriptions in HP\n",
      "Costume Ideas for Friends\n",
      "New chat\n",
      "Synonyms for \"show\"\n",
      "I'm here to help you with any questions or problems you have! Whether you need information, assistance with a task, or just want\n",
      "Spring's Simple Poetic Beauty\n",
      "Mirrors vs. Foil S'mores\n",
      "Sci-fi Story\n",
      "Sci-fi Story V2\n",
      "Understood. How can I assist you today?\n",
      "History Essay Global Statements\n",
      "Analysis\n",
      "Gender-neutral Name Suggestions\n",
      "I understand you would like to know the title of the conversation. The title for this conversation is: \"Donut vs. Pie Charts\"\n",
      "New chat\n",
      "New chat\n",
      "Hogwarts First Year CYOA\n",
      "Appropriate Puppy Photo?\n",
      "Why the Moon Turns Red\n",
      "Using \"P\" for Months\n",
      "Renew Plus\n",
      "\n",
      "User\n",
      "Son Pham\n",
      "Default (GPT-3.5)\n",
      "\n",
      "User\n",
      "Take a deep breath, then work out the below questions step by step.\n",
      "\n",
      "Explain the code for me:\n",
      "\n",
      "import streamlit as st\n",
      "\n",
      "\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.schema import (\n",
      "    AIMessage,\n",
      "    HumanMessage,\n",
      "    SystemMessage\n",
      ")\n",
      "\n",
      "# From here down is all the StreamLit UI.\n",
      "st.set_page_config(page_title=\"LangChain Demo\", page_icon=\":robot:\")\n",
      "st.header(\"Hey, I'm your Chat GPT\")\n",
      "\n",
      "\n",
      "\n",
      "if \"sessionMessages\" not in st.session_state:\n",
      "     st.session_state.sessionMessages = [\n",
      "        SystemMessage(content=\"You are a helpful assistant.\")\n",
      "    ]\n",
      "\n",
      "\n",
      "\n",
      "def load_answer(question):\n",
      "\n",
      "    st.session_state.sessionMessages.append(HumanMessage(content=question))\n",
      "\n",
      "    assistant_answer  = chat(st.session_state.sessionMessages )\n",
      "\n",
      "    st.session_state.sessionMessages.append(AIMessage(content=assistant_answer.content))\n",
      "\n",
      "    return assistant_answer.content\n",
      "\n",
      "\n",
      "def get_text():\n",
      "    input_text = st.text_input(\"You: \", key= input)\n",
      "    return input_text\n",
      "\n",
      "\n",
      "chat = ChatOpenAI(temperature=0)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "user_input=get_text()\n",
      "submit = st.button('Generate')  \n",
      "\n",
      "if submit:\n",
      "    \n",
      "    response = load_answer(user_input)\n",
      "    st.subheader(\"Answer:\")\n",
      "\n",
      "    st.write(response,key= 1)\n",
      "ChatGPT\n",
      "The provided code is for a simple Streamlit app that interfaces with a chat model. Streamlit is a Python library used to create web apps for data science and machine learning. The app uses a custom chat model from the langchain.chat_models package and several custom message schema classes to handle the conversation. Let's break down the code piece by piece.\n",
      "\n",
      "Imports\n",
      "python\n",
      "Copy code\n",
      "import streamlit as st\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.schema import (\n",
      "    AIMessage,\n",
      "    HumanMessage,\n",
      "    SystemMessage\n",
      ")\n",
      "streamlit as st: Importing the Streamlit library for web UI.\n",
      "ChatOpenAI: Importing a chat model class from a custom package.\n",
      "AIMessage, HumanMessage, SystemMessage: Importing classes that likely define the structure of messages in a chat.\n",
      "Streamlit Configuration\n",
      "python\n",
      "Copy code\n",
      "st.set_page_config(page_title=\"LangChain Demo\", page_icon=\":robot:\")\n",
      "st.header(\"Hey, I'm your Chat GPT\")\n",
      "st.set_page_config(...): Setting the page title and icon.\n",
      "st.header(...): Setting a header text on the webpage.\n",
      "Session State Initialization\n",
      "python\n",
      "Copy code\n",
      "if \"sessionMessages\" not in st.session_state:\n",
      "    st.session_state.sessionMessages = [\n",
      "        SystemMessage(content=\"You are a helpful assistant.\")\n",
      "    ]\n",
      "This block initializes a session state variable sessionMessages if it's not already present. The variable is initialized with a SystemMessage object.\n",
      "Function Definitions\n",
      "load_answer\n",
      "python\n",
      "Copy code\n",
      "def load_answer(question):\n",
      "    st.session_state.sessionMessages.append(HumanMessage(content=question))\n",
      "    assistant_answer  = chat(st.session_state.sessionMessages)\n",
      "    st.session_state.sessionMessages.append(AIMessage(content=assistant_answer.content))\n",
      "    return assistant_answer.content\n",
      "Appends the user's question to sessionMessages.\n",
      "Invokes the chat model to get a response.\n",
      "Appends the assistant's response to sessionMessages.\n",
      "Returns the assistant's response.\n",
      "get_text\n",
      "python\n",
      "Copy code\n",
      "def get_text():\n",
      "    input_text = st.text_input(\"You: \", key= input)\n",
      "    return input_text\n",
      "Creates a text input box in the Streamlit UI where the user can type.\n",
      "Returns the text entered by the user.\n",
      "Initialize Chat Model\n",
      "python\n",
      "Copy code\n",
      "chat = ChatOpenAI(temperature=0)\n",
      "Initializes a chat model object with temperature=0.\n",
      "Main Interaction Logic\n",
      "python\n",
      "Copy code\n",
      "user_input=get_text()\n",
      "submit = st.button('Generate')  \n",
      "if submit:\n",
      "    response = load_answer(user_input)\n",
      "    st.subheader(\"Answer:\")\n",
      "    st.write(response, key=1)\n",
      "get_text() gets the user's input.\n",
      "Creates a \"Generate\" button in the Streamlit UI.\n",
      "When the button is clicked, the assistant's response is generated and displayed.\n",
      "Key Notes\n",
      "st.session_state: Allows storing states across interactions.\n",
      "st.text_input(...), st.button(...), st.subheader(...), st.write(...): Streamlit functions for UI elements.\n",
      "key=: Specifies a unique key for the Streamlit widget.\n",
      "This code provides a basic interface for a chat assistant within a Streamlit app. The assistant uses the ChatOpenAI class from the langchain.chat_models package to generate responses.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Regenerate\n",
      "Send a message\n",
      "\n",
      "Free Research Preview. ChatGPT may produce inaccurate information about people, places, or facts. ChatGPT September 25 Version\n",
      "\n",
      "?\n",
      "ChatGPT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the Edge window\n",
    "windows = pyautogui.getWindowsWithTitle('Edge')\n",
    "if not windows:\n",
    "    print(\"Edge is not open\")\n",
    "else:\n",
    "    # Bring the Edge window to the foreground\n",
    "    windows[0].activate()\n",
    "\n",
    "    # Wait for the window to be active\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Select all text\n",
    "    pyautogui.hotkey('ctrl', 'a')  # Use 'cmd' instead of 'ctrl' on macOS\n",
    "\n",
    "    # Copy the selected text\n",
    "    pyautogui.hotkey('ctrl', 'c')  # Use 'cmd' instead of 'ctrl' on macOS\n",
    "\n",
    "    # Wait for the clipboard to be updated\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    # Get the copied text\n",
    "    copied_text = pyperclip.paste()\n",
    "\n",
    "    print(copied_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract user and chatGPT response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chat history\\r\\nNew Chat\\r\\nClose sidebar\\r\\nToday\\r\\nShort Starry Night Poem\\r\\nLearn English Presentation Skills\\r\\nHeritage, Nationality, and Residence\\r\\nYesterday\\r\\nHello and assistance.\\r\\nPrevious 7 Days\\r\\nNew chat\\r\\nBible and Palestine Connection\\r\\nXuất hiện khoa học dữ liệu\\r\\nBible: Canaan, Philistines, Palestine\\r\\nMeaning of Edo\\r\\nJapan\\'s Waste Classification System\\r\\nPrevious 30 Days\\r\\nNew chat\\r\\nNew chat\\r\\nNew chat\\r\\nCursed Child Canon Discussion\\r\\nNew chat\\r\\nFeeding Guppies for Vacation\\r\\nClarify Criteria for Rating\\r\\nSafe Burger Storage Time\\r\\nPython Harry Potter Quiz\\r\\nDisney Princess Quote Game\\r\\nFix UnboundLocalError using global\\r\\nLinking Tables in Power BI\\r\\nLangchain for Local Models\\r\\nMax_length Solution for Langchain\\r\\nAI Chat Support\\r\\nBlack & White Effects\\r\\nFixing \"conda not recognized\"\\r\\nTheoretical Rankings\\r\\nCode Refactoring: Streamlit Application\\r\\nSentence vs Word Embeddings\\r\\nNew chat\\r\\nTransplanting succulents safely.\\r\\nSeptember\\r\\nGPT Chat in Streamlit\\r\\n\\r\\n\\r\\nPhosphorus Appearance Clarified\\r\\nFantasy Potion Ideas\\r\\nPotion-making game: 10 elixirs\\r\\nCharacter Descriptions in HP\\r\\nCostume Ideas for Friends\\r\\nNew chat\\r\\nSynonyms for \"show\"\\r\\nI\\'m here to help you with any questions or problems you have! Whether you need information, assistance with a task, or just want\\r\\nSpring\\'s Simple Poetic Beauty\\r\\nMirrors vs. Foil S\\'mores\\r\\nSci-fi Story\\r\\nSci-fi Story V2\\r\\nUnderstood. How can I assist you today?\\r\\nHistory Essay Global Statements\\r\\nAnalysis\\r\\nGender-neutral Name Suggestions\\r\\nI understand you would like to know the title of the conversation. The title for this conversation is: \"Donut vs. Pie Charts\"\\r\\nNew chat\\r\\nNew chat\\r\\nHogwarts First Year CYOA\\r\\nAppropriate Puppy Photo?\\r\\nWhy the Moon Turns Red\\r\\nUsing \"P\" for Months\\r\\nRenew Plus\\r\\n\\r\\nUser\\r\\nSon Pham\\r\\nDefault (GPT-3.5)\\r\\n\\r\\nUser\\r\\nTake a deep breath, then work out the below questions step by step.\\r\\n\\r\\nExplain the code for me:\\r\\n\\r\\nimport streamlit as st\\r\\n\\r\\n\\r\\nfrom langchain.chat_models import ChatOpenAI\\r\\nfrom langchain.schema import (\\r\\n    AIMessage,\\r\\n    HumanMessage,\\r\\n    SystemMessage\\r\\n)\\r\\n\\r\\n# From here down is all the StreamLit UI.\\r\\nst.set_page_config(page_title=\"LangChain Demo\", page_icon=\":robot:\")\\r\\nst.header(\"Hey, I\\'m your Chat GPT\")\\r\\n\\r\\n\\r\\n\\r\\nif \"sessionMessages\" not in st.session_state:\\r\\n     st.session_state.sessionMessages = [\\r\\n        SystemMessage(content=\"You are a helpful assistant.\")\\r\\n    ]\\r\\n\\r\\n\\r\\n\\r\\ndef load_answer(question):\\r\\n\\r\\n    st.session_state.sessionMessages.append(HumanMessage(content=question))\\r\\n\\r\\n    assistant_answer  = chat(st.session_state.sessionMessages )\\r\\n\\r\\n    st.session_state.sessionMessages.append(AIMessage(content=assistant_answer.content))\\r\\n\\r\\n    return assistant_answer.content\\r\\n\\r\\n\\r\\ndef get_text():\\r\\n    input_text = st.text_input(\"You: \", key= input)\\r\\n    return input_text\\r\\n\\r\\n\\r\\nchat = ChatOpenAI(temperature=0)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nuser_input=get_text()\\r\\nsubmit = st.button(\\'Generate\\')  \\r\\n\\r\\nif submit:\\r\\n    \\r\\n    response = load_answer(user_input)\\r\\n    st.subheader(\"Answer:\")\\r\\n\\r\\n    st.write(response,key= 1)\\r\\nChatGPT\\r\\nThe provided code is for a simple Streamlit app that interfaces with a chat model. Streamlit is a Python library used to create web apps for data science and machine learning. The app uses a custom chat model from the langchain.chat_models package and several custom message schema classes to handle the conversation. Let\\'s break down the code piece by piece.\\r\\n\\r\\nImports\\r\\npython\\r\\nCopy code\\r\\nimport streamlit as st\\r\\nfrom langchain.chat_models import ChatOpenAI\\r\\nfrom langchain.schema import (\\r\\n    AIMessage,\\r\\n    HumanMessage,\\r\\n    SystemMessage\\r\\n)\\r\\nstreamlit as st: Importing the Streamlit library for web UI.\\r\\nChatOpenAI: Importing a chat model class from a custom package.\\r\\nAIMessage, HumanMessage, SystemMessage: Importing classes that likely define the structure of messages in a chat.\\r\\nStreamlit Configuration\\r\\npython\\r\\nCopy code\\r\\nst.set_page_config(page_title=\"LangChain Demo\", page_icon=\":robot:\")\\r\\nst.header(\"Hey, I\\'m your Chat GPT\")\\r\\nst.set_page_config(...): Setting the page title and icon.\\r\\nst.header(...): Setting a header text on the webpage.\\r\\nSession State Initialization\\r\\npython\\r\\nCopy code\\r\\nif \"sessionMessages\" not in st.session_state:\\r\\n    st.session_state.sessionMessages = [\\r\\n        SystemMessage(content=\"You are a helpful assistant.\")\\r\\n    ]\\r\\nThis block initializes a session state variable sessionMessages if it\\'s not already present. The variable is initialized with a SystemMessage object.\\r\\nFunction Definitions\\r\\nload_answer\\r\\npython\\r\\nCopy code\\r\\ndef load_answer(question):\\r\\n    st.session_state.sessionMessages.append(HumanMessage(content=question))\\r\\n    assistant_answer  = chat(st.session_state.sessionMessages)\\r\\n    st.session_state.sessionMessages.append(AIMessage(content=assistant_answer.content))\\r\\n    return assistant_answer.content\\r\\nAppends the user\\'s question to sessionMessages.\\r\\nInvokes the chat model to get a response.\\r\\nAppends the assistant\\'s response to sessionMessages.\\r\\nReturns the assistant\\'s response.\\r\\nget_text\\r\\npython\\r\\nCopy code\\r\\ndef get_text():\\r\\n    input_text = st.text_input(\"You: \", key= input)\\r\\n    return input_text\\r\\nCreates a text input box in the Streamlit UI where the user can type.\\r\\nReturns the text entered by the user.\\r\\nInitialize Chat Model\\r\\npython\\r\\nCopy code\\r\\nchat = ChatOpenAI(temperature=0)\\r\\nInitializes a chat model object with temperature=0.\\r\\nMain Interaction Logic\\r\\npython\\r\\nCopy code\\r\\nuser_input=get_text()\\r\\nsubmit = st.button(\\'Generate\\')  \\r\\nif submit:\\r\\n    response = load_answer(user_input)\\r\\n    st.subheader(\"Answer:\")\\r\\n    st.write(response, key=1)\\r\\nget_text() gets the user\\'s input.\\r\\nCreates a \"Generate\" button in the Streamlit UI.\\r\\nWhen the button is clicked, the assistant\\'s response is generated and displayed.\\r\\nKey Notes\\r\\nst.session_state: Allows storing states across interactions.\\r\\nst.text_input(...), st.button(...), st.subheader(...), st.write(...): Streamlit functions for UI elements.\\r\\nkey=: Specifies a unique key for the Streamlit widget.\\r\\nThis code provides a basic interface for a chat assistant within a Streamlit app. The assistant uses the ChatOpenAI class from the langchain.chat_models package to generate responses.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nRegenerate\\r\\nSend a message\\r\\n\\r\\nFree Research Preview. ChatGPT may produce inaccurate information about people, places, or facts. ChatGPT September 25 Version\\r\\n\\r\\n?\\r\\nChatGPT\\r\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "copied_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input 1', 'input 2', 'input 3']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "input_string = \"\"\"Some text User input 1 \n",
    "ChatGPT\n",
    "response 1 \n",
    "User\n",
    "input 2\n",
    "ChatGPT\n",
    "response 2\n",
    "User\n",
    "input 3\n",
    "ChatGPT\n",
    "response 3\"\"\"\n",
    "\n",
    "matches = re.findall(r\"User(.*?)ChatGPT\", input_string, re.DOTALL)\n",
    "user_inputs = [match.strip() for match in matches]\n",
    "\n",
    "print(user_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some text User input 1 \\nChatGPT \\nresponse 1 \\nUser \\ninput 2 \\nChatGPT \\nresponse 2 \\nUser \\ninput 3 \\nChatGPT \\nresponse 3'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Son Pham\\r\\nDefault (GPT-3.5)\\r\\n\\r\\nUser\\r\\nTake a deep breath, then work out the below questions step by step.\\r\\n\\r\\nExplain the code for me:\\r\\n\\r\\nimport streamlit as st\\r\\n\\r\\n\\r\\nfrom langchain.chat_models import ChatOpenAI\\r\\nfrom langchain.schema import (\\r\\n    AIMessage,\\r\\n    HumanMessage,\\r\\n    SystemMessage\\r\\n)\\r\\n\\r\\n# From here down is all the StreamLit UI.\\r\\nst.set_page_config(page_title=\"LangChain Demo\", page_icon=\":robot:\")\\r\\nst.header(\"Hey, I\\'m your Chat GPT\")\\r\\n\\r\\n\\r\\n\\r\\nif \"sessionMessages\" not in st.session_state:\\r\\n     st.session_state.sessionMessages = [\\r\\n        SystemMessage(content=\"You are a helpful assistant.\")\\r\\n    ]\\r\\n\\r\\n\\r\\n\\r\\ndef load_answer(question):\\r\\n\\r\\n    st.session_state.sessionMessages.append(HumanMessage(content=question))\\r\\n\\r\\n    assistant_answer  = chat(st.session_state.sessionMessages )\\r\\n\\r\\n    st.session_state.sessionMessages.append(AIMessage(content=assistant_answer.content))\\r\\n\\r\\n    return assistant_answer.content\\r\\n\\r\\n\\r\\ndef get_text():\\r\\n    input_text = st.text_input(\"You: \", key= input)\\r\\n    return input_text\\r\\n\\r\\n\\r\\nchat = ChatOpenAI(temperature=0)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nuser_input=get_text()\\r\\nsubmit = st.button(\\'Generate\\')  \\r\\n\\r\\nif submit:\\r\\n    \\r\\n    response = load_answer(user_input)\\r\\n    st.subheader(\"Answer:\")\\r\\n\\r\\n    st.write(response,key= 1)']\n"
     ]
    }
   ],
   "source": [
    "matches = re.findall(r\"User(.*?)ChatGPT\", copied_text, re.DOTALL)\n",
    "user_inputs = [match.strip() for match in matches]\n",
    "\n",
    "print(user_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Son Pham\n",
      "Default (GPT-3.5)\n",
      "\n",
      "User\n",
      "Take a deep breath, then work out the below questions step by step.\n",
      "\n",
      "Explain the code for me:\n",
      "\n",
      "import streamlit as st\n",
      "\n",
      "\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.schema import (\n",
      "    AIMessage,\n",
      "    HumanMessage,\n",
      "    SystemMessage\n",
      ")\n",
      "\n",
      "# From here down is all the StreamLit UI.\n",
      "st.set_page_config(page_title=\"LangChain Demo\", page_icon=\":robot:\")\n",
      "st.header(\"Hey, I'm your Chat GPT\")\n",
      "\n",
      "\n",
      "\n",
      "if \"sessionMessages\" not in st.session_state:\n",
      "     st.session_state.sessionMessages = [\n",
      "        SystemMessage(content=\"You are a helpful assistant.\")\n",
      "    ]\n",
      "\n",
      "\n",
      "\n",
      "def load_answer(question):\n",
      "\n",
      "    st.session_state.sessionMessages.append(HumanMessage(content=question))\n",
      "\n",
      "    assistant_answer  = chat(st.session_state.sessionMessages )\n",
      "\n",
      "    st.session_state.sessionMessages.append(AIMessage(content=assistant_answer.content))\n",
      "\n",
      "    return assistant_answer.content\n",
      "\n",
      "\n",
      "def get_text():\n",
      "    input_text = st.text_input(\"You: \", key= input)\n",
      "    return input_text\n",
      "\n",
      "\n",
      "chat = ChatOpenAI(temperature=0)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "user_input=get_text()\n",
      "submit = st.button('Generate')  \n",
      "\n",
      "if submit:\n",
      "    \n",
      "    response = load_answer(user_input)\n",
      "    st.subheader(\"Answer:\")\n",
      "\n",
      "    st.write(response,key= 1)\n"
     ]
    }
   ],
   "source": [
    "print(user_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\development\\screen_control\\app.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/development/screen_control/app.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(user_inputs[\u001b[39m1\u001b[39;49m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(user_inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "location_search_bar = {'x': 750, 'y': 1055}\n",
    "location_browser_address_bar = {'x': 400, 'y': 65}\n",
    "web_browser = 'Edge'\n",
    "url = 'https://chat.openai.com/'\n",
    "\n",
    "def open_webpage(location_search_bar, location_browser_address_bar, web_browser, url):\n",
    "    # Get a list of all currently open Edge windows\n",
    "    old_windows = pyautogui.getWindowsWithTitle(web_browser)\n",
    "\n",
    "    # Step 1: Open Edge browser\n",
    "    # Location of the search bar on the screen\n",
    "    pyautogui.click(x=location_search_bar[\"x\"], y=location_search_bar[\"y\"])\n",
    "\n",
    "    time.sleep(1)  # wait for the search bar to open\n",
    "    pyautogui.write(web_browser)\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "    time.sleep(2)  # wait for the browser to open\n",
    "\n",
    "    # Get a list of all currently open Edge windows\n",
    "    new_windows = pyautogui.getWindowsWithTitle(web_browser)\n",
    "\n",
    "    # Find the new window that wasn't in the old list\n",
    "    new_window = None\n",
    "    for window in new_windows:\n",
    "        if window not in old_windows:\n",
    "            new_window = window\n",
    "            break\n",
    "\n",
    "    if new_window is None:\n",
    "        print(\"Could not find new {browser} window\")\n",
    "        return\n",
    "\n",
    "    # Step 1.5: Move the new Edge browser window to the first monitor\n",
    "    # Note: You might need to adjust the coordinates (x, y) depending on your screen resolution\n",
    "    new_window.moveTo(100, 100)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Step 2: Maximize the new Edge browser window\n",
    "    pyautogui.hotkey('alt', 'space')\n",
    "    time.sleep(1)  # wait for the window menu to open\n",
    "    pyautogui.press('x')\n",
    "\n",
    "    # Step 3: Click on the browser address bar\n",
    "    pyautogui.click(x=location_browser_address_bar[\"x\"], y=location_browser_address_bar[\"y\"])  \n",
    "\n",
    "    # Step 4: Type the URL\n",
    "    pyautogui.write(url)\n",
    "\n",
    "    # Step 5: Press enter to go to the webpage\n",
    "    pyautogui.press('enter')\n",
    "\n",
    "open_webpage(location_search_bar, location_browser_address_bar, web_browser, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point(x=819, y=959)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyautogui.position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import mss\n",
    "\n",
    "# Get the information of the second monitor\n",
    "monitor = mss.mss().monitors[1]\n",
    "\n",
    "# Move the mouse to the center of the second monitor\n",
    "pyautogui.moveTo(monitor[\"left\"] + monitor[\"width\"] // 2, monitor[\"top\"] + monitor[\"height\"] // 2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
